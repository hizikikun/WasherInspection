#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨¹è„‚ãƒ¯ãƒƒã‚·ãƒ£ãƒ¼æ¬ é™¥æ¤œæŸ»ã‚·ã‚¹ãƒ†ãƒ 
"""

import cv2
import numpy as np
import tensorflow as tf
from pathlib import Path
import os
import json
import threading
import time
from datetime import datetime

class RealImageInspectionSystem:
    def __init__(self):
        self.model = None
        self.camera = None
        self.camera_id = 0  # ã‚«ãƒ¡ãƒ©0å›ºå®š
        self.feedback_count = 0
        self.class_names = ["è‰¯å“", "æ¬ ã‘", "é»’ç‚¹", "å‚·"]
        self.class_folders = ["good", "chipping", "black_spot", "scratch"]
        self.load_model()
        
        # å››ç‚¹é¸æŠæ©Ÿèƒ½
        self.selection_mode = False
        self.selection_points = []
        self.current_frame = None
        self.training_thread = None
        self.is_training = False
        self.last_prediction = "---"
        self.prediction_stable_count = 0
        
        self.target_width = 1920
        self.target_height = 1080
        
        # UIè¨­å®š
        self.window_title = "Resin Washer Inspection - Real Image Model"
        
    def load_model(self):
        """å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            # å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
            model_path = "real_image_defect_model/defect_classifier_model.h5"
            if os.path.exists(model_path):
                self.model = tf.keras.models.load_model(model_path)
                print(f"å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {model_path}")
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€è‰¯ãƒ¢ãƒ‡ãƒ«
                fallback_path = "best_real_defect_model.h5"
                if os.path.exists(fallback_path):
                    self.model = tf.keras.models.load_model(fallback_path)
                    print(f"æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {fallback_path}")
                else:
                    print(f"è­¦å‘Š: AIãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    self.model = None
        except Exception as e:
            print(f"AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            self.model = None

    def initialize_camera(self):
        """ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã¨è¨­å®š"""
        if self.camera:
            self.camera.release()
        
        print(f"ã‚«ãƒ¡ãƒ©ID {self.camera_id} ã‚’åˆæœŸåŒ–ä¸­...")
        self.camera = cv2.VideoCapture(self.camera_id, cv2.CAP_DSHOW)
        
        if not self.camera.isOpened():
            print(f"ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ¡ãƒ©ID {self.camera_id} ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚")
            return False

        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, self.target_width)
        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, self.target_height)
        
        actual_width = int(self.camera.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT))
        print(f"ã‚«ãƒ¡ãƒ©ID {self.camera_id} ã‚’ {actual_width}x{actual_height} ã§é–‹ãã¾ã—ãŸã€‚")
        
        return True

    def preprocess_frame(self, frame):
        """AIãƒ¢ãƒ‡ãƒ«ç”¨ã®å‰å‡¦ç†"""
        if frame is None:
            return None
        
        img = cv2.resize(frame, (224, 224))
        img = np.expand_dims(img, axis=0)
        img = img / 255.0
        return img

    def predict_defect(self, frame):
        """æ¬ é™¥ã‚’äºˆæ¸¬ï¼ˆå®‰å®šåŒ–å‡¦ç†ä»˜ãï¼‰"""
        if self.model is None or frame is None:
            return "??? unknown", 0.0

        preprocessed_img = self.preprocess_frame(frame)
        if preprocessed_img is None:
            return "??? unknown", 0.0

        predictions = self.model.predict(preprocessed_img)
        score = np.max(predictions)
        class_id = np.argmax(predictions)
        
        if score < 0.5:  # ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯ unknown
            return "??? unknown", score
        
        predicted_class = self.class_names[class_id]
        
        # äºˆæ¸¬ã®å®‰å®šåŒ–å‡¦ç†
        if predicted_class == self.last_prediction:
            self.prediction_stable_count += 1
        else:
            self.prediction_stable_count = 0
            self.last_prediction = predicted_class
        
        # 3å›é€£ç¶šã§åŒã˜äºˆæ¸¬ãŒå‡ºã‚‹ã¾ã§å¾…ã¤
        if self.prediction_stable_count < 3:
            return self.last_prediction, score
        
        return predicted_class, score

    def mouse_callback(self, event, x, y, flags, param):
        """ãƒã‚¦ã‚¹ã‚¯ãƒªãƒƒã‚¯ã§å››ç‚¹é¸æŠ"""
        if not self.selection_mode:
            return
            
        if event == cv2.EVENT_LBUTTONDOWN:
            if len(self.selection_points) < 4:
                self.selection_points.append((x, y))
                print(f"ç‚¹{len(self.selection_points)}: ({x}, {y})")
                
                if len(self.selection_points) == 4:
                    print("å››ç‚¹é¸æŠå®Œäº†ï¼1-4ã‚­ãƒ¼ã§ã‚¯ãƒ©ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                    self.selection_mode = False

    def save_images(self, class_id):
        """é¸æŠç¯„å›²ã¨å…¨ä½“ç”»åƒã‚’ä¿å­˜"""
        if len(self.selection_points) != 4 or self.current_frame is None:
            print("ã‚¨ãƒ©ãƒ¼: å››ç‚¹ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return
            
        try:
            # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            class_name = self.class_folders[class_id]
            save_dir = Path(f"C:/Users/tomoh/WasherInspection/cs_AItraining_data/resin/{class_name}/{class_name}_extra_training")
            save_dir.mkdir(parents=True, exist_ok=True)
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # å…¨ä½“ç”»åƒã‚’ä¿å­˜
            full_image_path = save_dir / f"full_{timestamp}.jpg"
            success1 = cv2.imwrite(str(full_image_path), self.current_frame)
            if success1:
                print(f"âœ… å…¨ä½“ç”»åƒã‚’ä¿å­˜: {full_image_path}")
            else:
                print(f"âŒ å…¨ä½“ç”»åƒã®ä¿å­˜ã«å¤±æ•—: {full_image_path}")
                return
            
            # é¸æŠç¯„å›²ã®ç”»åƒã‚’ä¿å­˜
            if len(self.selection_points) == 4:
                # å››ç‚¹ã‹ã‚‰çŸ©å½¢ã‚’è¨ˆç®—
                points = np.array(self.selection_points, dtype=np.int32)
                x_min, y_min = np.min(points, axis=0)
                x_max, y_max = np.max(points, axis=0)
                
                # ç¯„å›²ã‚’å°‘ã—æ‹¡å¼µ
                margin = 10
                x_min = max(0, x_min - margin)
                y_min = max(0, y_min - margin)
                x_max = min(self.current_frame.shape[1], x_max + margin)
                y_max = min(self.current_frame.shape[0], y_max + margin)
                
                # é¸æŠç¯„å›²ã‚’åˆ‡ã‚Šå‡ºã—
                cropped_image = self.current_frame[y_min:y_max, x_min:x_max]
                
                # é¸æŠç¯„å›²ç”»åƒã‚’ä¿å­˜
                cropped_image_path = save_dir / f"cropped_{timestamp}.jpg"
                success2 = cv2.imwrite(str(cropped_image_path), cropped_image)
                if success2:
                    print(f"âœ… é¸æŠç¯„å›²ç”»åƒã‚’ä¿å­˜: {cropped_image_path}")
                else:
                    print(f"âŒ é¸æŠç¯„å›²ç”»åƒã®ä¿å­˜ã«å¤±æ•—: {cropped_image_path}")
                    return
            
            # é¸æŠçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            self.selection_points = []
            self.selection_mode = False
            print(f"ğŸ‰ {self.class_names[class_id]}ã‚¯ãƒ©ã‚¹ã®ç”»åƒã‚»ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
            
        except Exception as e:
            print(f"âŒ ç”»åƒä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    def start_training(self):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹"""
        if self.training_thread and self.training_thread.is_alive():
            print("âš ï¸ æ—¢ã«å­¦ç¿’ä¸­ã§ã™ã€‚")
            return
            
        self.is_training = True
        self.training_thread = threading.Thread(target=self._train_model)
        self.training_thread.daemon = True
        self.training_thread.start()
        print("ğŸš€ ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸ...")

    def _train_model(self):
        """å®Ÿéš›ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°å‡¦ç†"""
        try:
            print("=== è¿½åŠ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ ===")
            
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            X_train, X_test, y_train, y_test = self._load_training_data()
            
            if X_train is None or len(X_train) == 0:
                print("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return
                
            # ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´
            self._retrain_model(X_train, X_test, y_train, y_test)
            
            print("=== ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº† ===")
            
        except Exception as e:
            print(f"âŒ å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        finally:
            self.is_training = False

    def _load_training_data(self):
        """è¿½åŠ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        all_images = []
        all_labels = []
        
        base_dir = Path("C:/Users/tomoh/WasherInspection/cs_AItraining_data/resin")
        
        for i, class_folder in enumerate(self.class_folders):
            class_path = base_dir / class_folder
            
            # é€šå¸¸ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
            if class_path.exists():
                for img_path in class_path.rglob("*.jpg"):
                    try:
                        img = cv2.imread(str(img_path))
                        if img is not None:
                            img = cv2.resize(img, (224, 224))
                            all_images.append(img)
                            all_labels.append(i)
                    except Exception as e:
                        print(f"ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {img_path}, {e}")
            
            # è¿½åŠ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
            extra_path = class_path / f"{class_folder}_extra_training"
            if extra_path.exists():
                for img_path in extra_path.glob("*.jpg"):
                    try:
                        img = cv2.imread(str(img_path))
                        if img is not None:
                            img = cv2.resize(img, (224, 224))
                            all_images.append(img)
                            all_labels.append(i)
                    except Exception as e:
                        print(f"è¿½åŠ ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {img_path}, {e}")
        
        if len(all_images) == 0:
            return None, None, None, None
            
        X = np.array(all_images)
        y = tf.keras.utils.to_categorical(np.array(all_labels), num_classes=len(self.class_names))
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=np.array(all_labels)
        )
        
        X_train = X_train / 255.0
        X_test = X_test / 255.0
        
        print(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(all_images)}æš")
        return X_train, X_test, y_train, y_test

    def _retrain_model(self, X_train, X_test, y_train, y_test):
        """ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´"""
        if self.model is None:
            print("ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return
            
        # å­¦ç¿’ç‡ã‚’ä¸‹ã’ã¦å¾®èª¿æ•´
        self.model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # æ—©æœŸåœæ­¢ã¨å­¦ç¿’ç‡èª¿æ•´
        callbacks = [
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)
        ]
        
        # å†è¨“ç·´
        history = self.model.fit(
            X_train, y_train,
            epochs=20,
            batch_size=16,
            validation_data=(X_test, y_test),
            callbacks=callbacks,
            verbose=1
        )
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        model_path = "real_image_defect_model/defect_classifier_model.h5"
        self.model.save(model_path)
        print(f"æ›´æ–°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {model_path}")
        
        # ç²¾åº¦ã‚’è©•ä¾¡
        loss, accuracy = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"æ›´æ–°å¾Œã®ç²¾åº¦: {accuracy:.4f}")

    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        if not self.initialize_camera():
            print("ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            return

        cv2.namedWindow(self.window_title, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.window_title, 1280, 720)
        
        # ãƒã‚¦ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¨­å®š
        cv2.setMouseCallback(self.window_title, self.mouse_callback)

        last_prediction_time = time.time()
        prediction_interval = 0.5  # 0.5ç§’é–“éš”ã§äºˆæ¸¬

        print("\n--- å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¤œæŸ»ã‚·ã‚¹ãƒ†ãƒ èµ·å‹• ---")
        print("ESCã‚­ãƒ¼ã§çµ‚äº†")
        print("UI: 2æšç›®ã®ç”»åƒãƒ‡ã‚¶ã‚¤ãƒ³")

        while True:
            ret, frame = self.camera.read()
            if not ret:
                print("ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
                break

            # ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜ï¼ˆç”»åƒä¿å­˜ç”¨ï¼‰
            self.current_frame = frame.copy()

            current_time = time.time()
            prediction_text = "---"
            confidence_score = 0.0
            
            if current_time - last_prediction_time >= prediction_interval:
                prediction_text, confidence_score = self.predict_defect(frame)
                last_prediction_time = current_time

            display_frame = frame.copy()  # UIæç”»ç”¨ã«ã‚³ãƒ”ãƒ¼
            
            # é¸æŠç‚¹ã‚’æç”»
            if self.selection_mode and len(self.selection_points) > 0:
                for i, point in enumerate(self.selection_points):
                    cv2.circle(display_frame, point, 5, (0, 255, 0), -1)
                    cv2.putText(display_frame, str(i+1), (point[0]+10, point[1]-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # é¸æŠä¸­ã®çŠ¶æ…‹è¡¨ç¤º
                cv2.putText(display_frame, f"é¸æŠä¸­: {len(self.selection_points)}/4", 
                           (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

            # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¿ã‚¤ãƒˆãƒ«
            cv2.setWindowTitle(self.window_title, self.window_title)

            # å·¦ä¸Šã®ãƒãƒŠãƒ¼ (Result: NG - Defect / Result: OK - è‰¯å“)
            if self.is_training:
                result_text = "å­¦ç¿’ä¸­..."
                banner_color = (0, 255, 255) # ã‚·ã‚¢ãƒ³ï¼ˆå­¦ç¿’ä¸­ï¼‰
            elif prediction_text == "è‰¯å“":
                result_text = "Result: OK - è‰¯å“"
                banner_color = (0, 255, 0) # ç·‘
            elif prediction_text == "??? unknown":
                result_text = "Result: ??? unknown"
                banner_color = (128, 128, 128) # ã‚°ãƒ¬ãƒ¼
            else:
                result_text = f"Result: NG - {prediction_text}" # NGã®å ´åˆã¯è©³ç´°è¡¨ç¤º
                banner_color = (0, 0, 255) # èµ¤ (NG)

            banner_width = 350
            banner_height = 70
            banner_x = 10
            banner_y = 10
            cv2.rectangle(display_frame, (banner_x, banner_y), (banner_x + banner_width, banner_y + banner_height), banner_color, -1)
            cv2.putText(display_frame, result_text, (banner_x + 10, banner_y + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)

            # ä¿¡é ¼åº¦è¡¨ç¤º
            if confidence_score > 0:
                confidence_text = f"Confidence: {confidence_score:.2f}"
                cv2.putText(display_frame, confidence_text, (banner_x + 10, banner_y + 65), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)

            # å·¦ä¸‹ã®é»’ã„ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«
            panel_width = 450
            panel_height = 140
            panel_x = 10
            panel_y = display_frame.shape[0] - panel_height - 10
            cv2.rectangle(display_frame, (panel_x, panel_y), (panel_x + panel_width, panel_y + panel_height), (0, 0, 0), -1)
            
            text_color = (255, 255, 255)  # ç™½
            font_scale = 0.7
            thickness = 2
            line_height = 25

            cv2.putText(display_frame, f"Feedback: {self.feedback_count}", (panel_x + 10, panel_y + line_height), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness, cv2.LINE_AA)
            cv2.putText(display_frame, "Controls", (panel_x + 10, panel_y + line_height * 2), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness, cv2.LINE_AA)
            cv2.putText(display_frame, "1:Good 2:Black 3:Chipped 4:Scratched", (panel_x + 10, panel_y + line_height * 3), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness, cv2.LINE_AA)
            cv2.putText(display_frame, "M:Select S:Train ESC:Exit", (panel_x + 10, panel_y + line_height * 4), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness, cv2.LINE_AA)
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
            cv2.putText(display_frame, "Model: Real Image Trained", (panel_x + 10, panel_y + line_height * 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1, cv2.LINE_AA)

            cv2.imshow(self.window_title, display_frame)

            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESCã‚­ãƒ¼ã§çµ‚äº†
                break
            elif key == ord('1'):  # è‰¯å“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
                self.feedback_count += 1
                print("è‰¯å“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²")
            elif key == ord('2'):  # é»’ç‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
                self.feedback_count += 1
                print("é»’ç‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²")
            elif key == ord('3'):  # æ¬ ã‘ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
                self.feedback_count += 1
                print("æ¬ ã‘ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²")
            elif key == ord('4'):  # å‚·ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
                self.feedback_count += 1
                print("å‚·ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²")
            elif key == ord('m') or key == ord('M'):  # Mã‚­ãƒ¼ã§é¸æŠãƒ¢ãƒ¼ãƒ‰é–‹å§‹
                self.selection_mode = True
                self.selection_points = []
                print("Mã‚­ãƒ¼: æ¬ é™¥é ˜åŸŸé¸æŠãƒ¢ãƒ¼ãƒ‰é–‹å§‹ - ãƒã‚¦ã‚¹ã§4ç‚¹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
            elif key == ord('s') or key == ord('S'):  # Sã‚­ãƒ¼ã§å­¦ç¿’é–‹å§‹
                print("Sã‚­ãƒ¼: ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹")
                self.start_training()
            elif key == ord('1'):  # è‰¯å“
                if len(self.selection_points) == 4:
                    self.save_images(0)
                else:
                    print("âš ï¸ å››ç‚¹é¸æŠå¾Œã«1ã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„")
            elif key == ord('2'):  # é»’ç‚¹
                if len(self.selection_points) == 4:
                    self.save_images(2)
                else:
                    print("âš ï¸ å››ç‚¹é¸æŠå¾Œã«2ã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„")
            elif key == ord('3'):  # æ¬ ã‘
                if len(self.selection_points) == 4:
                    self.save_images(1)
                else:
                    print("âš ï¸ å››ç‚¹é¸æŠå¾Œã«3ã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„")
            elif key == ord('4'):  # å‚·
                if len(self.selection_points) == 4:
                    self.save_images(3)
                else:
                    print("âš ï¸ å››ç‚¹é¸æŠå¾Œã«4ã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„")

        self.camera.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    system = RealImageInspectionSystem()
    system.run()
